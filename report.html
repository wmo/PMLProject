<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Willem Moors" />
  <title>PML Project - Practical Machine Learning: Project</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; }
code > span.ch { color: #008080; }
code > span.st { color: #008080; }
code > span.co { color: #008000; }
code > span.ot { color: #ff4000; }
code > span.al { color: #ff0000; }
code > span.er { font-weight: bold; }
  </style>
  <link rel="stylesheet" href="markdown.css" type="text/css" />
</head>
<body>
<div id="header">
<h1 class="title">Practical Machine Learning: Project</h1>
<h2 class="author">Willem Moors</h2>
</div>
<h1 id="introduction">Introduction</h1>
<p><em>Assignment</em> : this project is about making predictions about what type of physical action was undertaken by a person being monitored by an activity monitoring device (eg. fitbit, fuelband, ...). The person(s) in question were asked to lift barbells correctly and incorrectly in 5 different ways. Depending on the data gathered by the monitoring device, a prediction should be made as to which action had been undertaken.</p>
<p>More information about the project and where the data comes from: <a href="http://groupware.les.inf.puc-rio.br/har">groupware.les.inf.puc-rio.br/har</a> (Weight Lifting Exercise Dataset).</p>
<h2 id="strategy">Strategy</h2>
<p>Outline of how to tackle the problem:</p>
<ul>
<li><p>check the given datasets, to see which columns make most chance of providing a correct response and which columns can be disregarded 'at-first-sight'. Subset accordingly.</p></li>
<li><p>clean/convert the data</p></li>
<li><p>split the data into training and testing data</p></li>
<li><p>apply the model on the training data and testing data.</p></li>
<li><p>judge from the training and testing error if the prediction is close enough, otherwise start over</p></li>
<li><p>finally apply the model on the challenge, and get the requested prediction</p></li>
</ul>
<p>The chosen prediction algorithm is &quot;randomForest&quot;, because it is one of the best performing algorithms.</p>
<p>Given are two files:</p>
<ul>
<li>pml-training.csv : the predictors plus the outcome, to train a model to. To be split into train and test (validate).</li>
<li>pml-testing.csv : the predictors but without the outcome, that is what needs to be predicted. Ie. this is the challenge data.</li>
</ul>
<h3 id="overview">Overview</h3>
<p>How the data from the given files is organized into dataframes and vectors: dataframes x.. contain predictors, while vectors y.. contain the outcome.</p>
<div class="figure">
<img src="data_objects.png" />
</div>
<p>Note: the above diagram may give the impression that the split into training and test data occurs at a fixed position, but in fact the group a row belongs to is chosen randomly.</p>
<h1 id="step-1-clean-and-subset-the-data">Step 1: clean and subset the data</h1>
<h2 id="training-data">Training data</h2>
<p>In this step we create a dataframe called <code>meta</code> which provides information about the given training data. It provides the selection criteria about which columns to include or exclude in the training data.</p>
<pre class="sourceCode r"><code class="sourceCode r">raw_df &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;pml-training.csv&quot;</span> , <span class="dt">sep=</span><span class="st">&quot;,&quot;</span>, <span class="dt">head=</span>T, <span class="dt">as.is=</span>T, <span class="dt">na.strings=</span><span class="st">&quot;NA&quot;</span>,
                     <span class="dt">quote=</span><span class="st">&#39;&quot;&#39;</span>,<span class="dt">stringsAsFactors=</span>T )

nc &lt;-<span class="st"> </span><span class="kw">ncol</span>(raw_df)
nr &lt;-<span class="st"> </span><span class="kw">nrow</span>(raw_df)

<span class="co"># loop over each column, gather some statistics</span>
vn &lt;-<span class="st"> </span><span class="kw">character</span>(nc)  <span class="co"># name of the column</span>
nac &lt;-<span class="st"> </span><span class="kw">numeric</span>(nc)   <span class="co"># number of NA cells in a column</span>
divc &lt;-<span class="st"> </span><span class="kw">numeric</span>(nc)  <span class="co"># number of cells in a column containing the &quot;DIV/0&quot; error flag</span>
blnk &lt;-<span class="st"> </span><span class="kw">numeric</span>(nc)  <span class="co"># number of cells in a column containing nothing (and are not NA) </span>
for (i in <span class="dv">1</span>:nc) { 
    vn[i]   &lt;-<span class="st"> </span><span class="kw">names</span>(raw_df)[i]
    nac[i]  &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="dv">100</span>*<span class="kw">length</span>(<span class="kw">which</span>(<span class="kw">is.na</span>(raw_df[,i])))/nr,<span class="dv">0</span>)
    divc[i] &lt;-<span class="st"> </span><span class="dv">0</span>
    blnk[i] &lt;-<span class="st"> </span><span class="dv">0</span>
    if (<span class="kw">class</span>(raw_df[,i])==<span class="st">&quot;character&quot;</span>) {  <span class="co"># count the DIV/0&#39;s and the blanks</span>
        divc[i]=<span class="st"> </span><span class="kw">round</span>(<span class="dv">100</span>*<span class="kw">length</span>(<span class="kw">which</span>(raw_df[,i]==<span class="st">&quot;#DIV/0!&quot;</span>))/nr,<span class="dv">0</span>)
        blnk[i]=<span class="st"> </span><span class="kw">round</span>(<span class="dv">100</span>*<span class="kw">length</span>(<span class="kw">which</span>(raw_df[,i]==<span class="st">&quot;&quot;</span>))/nr,<span class="dv">0</span>)
    }
} 
meta &lt;-<span class="st"> </span><span class="kw">data.frame</span>(vn,nac,divc,blnk)
meta$tot=meta$nac+meta$divc+meta$blnk
<span class="co"># manually selected columns to be excluded</span>
meta[meta$vn %in%<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;X&quot;</span>,<span class="st">&quot;raw_timestamp_part_1&quot;</span>, <span class="st">&quot;raw_timestamp_part_2&quot;</span>, 
                    <span class="st">&quot;cvtd_timestamp&quot;</span>,<span class="st">&quot;classe&quot;</span>),<span class="st">&quot;tot&quot;</span>]=<span class="dv">100</span></code></pre>
<p>The above dataframe counts :</p>
<ul>
<li>how many NA's occur in a column</li>
<li>how often the label &quot;#DIV/0!&quot; occurs in a column (which prevented the auto-conversion of the column to numeric)</li>
<li>how often the text is blank in a column</li>
</ul>
<p>These counts are not expressed in absolute numbers, but in percentages, to make it easier to compare.</p>
<p>A number of columns were manually selected to be excluded (eg. &quot;raw_timestamp_part_1&quot; because of timestamp data)</p>
<p>The selected columns that we are continuing with, are the ones in above dataframe that have a total (column 'tot') score of less than 5.</p>
<pre class="sourceCode r"><code class="sourceCode r">selcols=<span class="st"> </span><span class="kw">as.vector</span>(meta[meta$tot&lt;<span class="dv">5</span>,<span class="st">&quot;vn&quot;</span>])

x_df=raw_df[,selcols]            <span class="co"># predictors (dataframe)</span>
y_v=<span class="kw">as.factor</span>(raw_df[,<span class="st">&quot;classe&quot;</span>]) <span class="co"># outcome    (vector)</span>

<span class="co"># column conversions to factor</span>
x_df$user_name &lt;-<span class="st"> </span><span class="kw">as.factor</span>(x_df$user_name)
x_df$new_window &lt;-<span class="st"> </span><span class="kw">as.factor</span>(x_df$new_window)

<span class="co"># all the other columns are converted to numeric </span>
for (i in <span class="dv">3</span>:<span class="kw">ncol</span>(x_df)) { 
    x_df[,i]&lt;-<span class="st"> </span><span class="kw">as.numeric</span>(x_df[,i])
}</code></pre>
<h2 id="challenge-data">Challenge data</h2>
<p>To the challenge data we apply exactly the same subsetting/cleaning that was done on the training data.</p>
<pre class="sourceCode r"><code class="sourceCode r">raw_df &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;pml-testing.csv&quot;</span> , <span class="dt">sep=</span><span class="st">&quot;,&quot;</span>, <span class="dt">head=</span>T, <span class="dt">as.is=</span>T, <span class="dt">na.strings=</span><span class="st">&quot;NA&quot;</span>,
                     <span class="dt">quote=</span><span class="st">&#39;&quot;&#39;</span>,<span class="dt">stringsAsFactors=</span>T )

xchallenge_df=raw_df[,selcols]  <span class="co"># restrict to only the selected columns </span>

<span class="co"># for the factor conversions use the same levels as the training data</span>
xchallenge_df$user_name=<span class="kw">factor</span>( xchallenge_df$user_name, <span class="kw">levels</span>(x_df$user_name ) )  
xchallenge_df$new_window=<span class="kw">factor</span>( xchallenge_df$new_window, <span class="kw">levels</span>(x_df$new_window) )  

<span class="co"># all the other columns are converted to numeric </span>
for (i in <span class="dv">3</span>:<span class="kw">ncol</span>(xchallenge_df)) { 
    xchallenge_df[,i]&lt;-<span class="st"> </span><span class="kw">as.numeric</span>(xchallenge_df[,i])
}</code></pre>
<h3 id="summary-of-step-1">Summary of step 1</h3>
<p>We've cleaned the data, and reduced the number of columns to a subset.</p>
<p>We'll proceed to the next step with these objects:</p>
<ul>
<li><code>x_df</code> : the variables (in a dataframe) to fit the model on</li>
<li><code>y_v</code> : the outcome data in a vector (ie. the 'classe' column of the original dataset)</li>
<li><code>x_challenge_df</code>: the variables we have to make a prediction for</li>
</ul>
<h1 id="step-2-fit-a-model">Step 2 : fit a model</h1>
<h2 id="split-the-training-data-into-training-and-test">Split the training data into training and test</h2>
<p>Randomly split the dataset into a training set and test set, in a 75% ratio.</p>
<ul>
<li>the training set will be used to fit the model</li>
<li>the test set will be used to validate the model</li>
</ul>
<p>Training set:</p>
<pre class="sourceCode r"><code class="sourceCode r">nr=<span class="kw">nrow</span>(x_df)
train=<span class="kw">sample</span>(<span class="dv">1</span>:nr,nr*.<span class="dv">75</span>)
xtrain_df=x_df[train,]
ytrain_v=y_v[train]</code></pre>
<p>Test set:</p>
<pre class="sourceCode r"><code class="sourceCode r">xtest_df=x_df[-train,] 
ytest_v=y_v[-train]</code></pre>
<h2 id="fit-a-randomforest-to-the-training-data">Fit a randomforest to the training data</h2>
<p>This is the most time-consuming step of the whole process: fitting a random forest.</p>
<pre class="sourceCode r"><code class="sourceCode r">fit=<span class="kw">randomForest</span>(xtrain_df,ytrain_v) 

<span class="kw">summary</span>(fit)</code></pre>
<pre><code>##                 Length Class  Mode     
## call                3  -none- call     
## type                1  -none- character
## predicted       14716  factor numeric  
## err.rate         3000  -none- numeric  
## confusion          30  -none- numeric  
## votes           73580  matrix numeric  
## oob.times       14716  -none- numeric  
## classes             5  -none- character
## importance         55  -none- numeric  
## importanceSD        0  -none- NULL     
## localImportance     0  -none- NULL     
## proximity           0  -none- NULL     
## ntree               1  -none- numeric  
## mtry                1  -none- numeric  
## forest             14  -none- list     
## y               14716  factor numeric  
## test                0  -none- NULL     
## inbag               0  -none- NULL</code></pre>
<h2 id="training-result-prediction">Training result prediction</h2>
<p>Make a prediction on the training data, to judge the correctness of the data.</p>
<pre class="sourceCode r"><code class="sourceCode r">ytrain_pred_v &lt;-<span class="st"> </span><span class="kw">predict</span>(fit,xtrain_df) 

numtrue=<span class="st"> </span><span class="kw">sum</span>(ytrain_v==ytrain_pred_v) 
percentcorrect=<span class="st"> </span><span class="kw">round</span>(<span class="dv">100</span>*numtrue/<span class="kw">length</span>(ytrain_v),<span class="dv">2</span>)</code></pre>
<p>The percent correctly predicted outcomes, when applied to the training data is <strong>100%</strong>.</p>
<p><strong>Confusion Matrix:</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confusionMatrix</span>( ytrain_v, ytrain_pred_v )$table</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 4166    0    0    0    0
##          B    0 2830    0    0    0
##          C    0    0 2569    0    0
##          D    0    0    0 2395    0
##          E    0    0    0    0 2756</code></pre>
<p>The values are on the diagonal are the correct predictions. The values off-diagonal are the errors. In this case all predictions are correct, a very promising result.</p>
<h2 id="test-result-prediction">Test result prediction</h2>
<pre class="sourceCode r"><code class="sourceCode r">ytest_pred_v &lt;-<span class="st"> </span><span class="kw">predict</span>(fit,xtest_df) 

numtrue=<span class="st"> </span><span class="kw">sum</span>(ytest_v==ytest_pred_v) 
percentcorrect=<span class="st"> </span><span class="kw">round</span>(<span class="dv">100</span>*numtrue/<span class="kw">length</span>(ytest_v),<span class="dv">2</span>)</code></pre>
<p>The percent correctly predicted outcomes, when applied to the testing data is <strong>99.74%</strong>. Which means that the out-of-sample error is <strong>0.26%</strong>.</p>
<p><strong>Confusion Matrix:</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confusionMatrix</span>( ytest_v, ytest_pred_v )$table</code></pre>
<pre><code>##           Reference
## Prediction    A    B    C    D    E
##          A 1414    0    0    0    0
##          B    0  965    2    0    0
##          C    0    3  848    2    0
##          D    0    0    4  817    0
##          E    0    0    0    2  849</code></pre>
<p>As expected the out-of-sample error is a bit bigger than that of the test result prediction: a few values can be found off-diagonal in the confusion matrix.</p>
<h3 id="summary-of-step-2">Summary of step 2</h3>
<p>The out of sample error is very close to 0, which makes this is a more-than-acceptable fit. No further tweaks need to be applied to the model, we can merrily proceed to the next step: predicting the challenge.</p>
<h1 id="step-3-predict-the-challenge">Step 3: predict the challenge</h1>
<p>This is the ultimate goal of the project, predict the <code>classe</code> outcome for the challenge data contained in the file <code>pml-testing.csv</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">ychallenge_pred_v &lt;-<span class="st"> </span><span class="kw">predict</span>(fit,xchallenge_df) 
ychallenge_pred_v </code></pre>
<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E</code></pre>
<p>This result was submitted to the MOOC's Coursera website for judgement. And it turned out to be 100% correct!</p>
</body>
</html>
